\documentclass[a4paper]{report}

\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{pstricks}
\usepackage{multido}
\usepackage{amsfonts}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage[spanish]{babel}
\usepackage{listings}
\lstdefinelanguage{json}{
  keywords={},
  keywordstyle=\bfseries,
  ndkeywords={},
  ndkeywordstyle=\bfseries,
  sensitive=false,
  comment=[l]{//},
  morecomment=[s]{/*}{*/},
  commentstyle=\ttfamily,
  stringstyle=\ttfamily,
  morestring=[b]',
  morestring=[b]"
}
\lstset{
   language=json,
   extendedchars=true,
   basicstyle=\footnotesize\ttfamily,
   showstringspaces=false,
   showspaces=false,
   tabsize=4,
   breaklines=true,
   showtabs=false,
   captionpos=b
}

\newcommand{\EQ}[2]
{\begin{equation}#1\label{#2}\end{equation}}

\newcommand{\PICTURE}[5]
{
	\begin{figure}[ht!]
		\centering
		\begin{picture}(#1,#2)
			#3
		\end{picture}
		\caption{#4.\label{#5}}
	\end{figure}
}

\newcommand{\PSPICTURE}[7]
{
	\begin{figure}[ht!]
		\centering
		\pspicture(#1,#2)(#3,#4)
			#5
		\endpspicture
		\caption{#6.\label{#7}}
	\end{figure}
}

\newcommand{\TABLE}[5]
{
	\begin{table}[ht!]
		\centering
		\caption{#4.\label{#5}}
		#1
		\begin{tabular}{#2}
			#3
		\end{tabular}
	\end{table}
}

\newcommand{\FIGII}[4]
{
	\begin{figure}[ht!]
		\centering
		\begin{tabular}{c}
			\includegraphics{#1} \\ \includegraphics{#2}
		\end{tabular}
		\caption{#3.\label{#4}}
	\end{figure}
}

\newcommand{\FIGIV}[6]
{
	\begin{figure}[ht!]
		\centering
		\begin{tabular}{cc}
			\includegraphics{#1} & \includegraphics{#2} \\
			\includegraphics{#3} & \includegraphics{#4}
		\end{tabular}
		\caption{#5.\label{#6}}
	\end{figure}
}

\newcommand{\FIGVI}[8]
{
	\begin{figure}[ht!]
		\centering
		\begin{tabular}{cc}
			\includegraphics{#1} & \includegraphics{#2} \\
			\includegraphics{#3} & \includegraphics{#4} \\
			\includegraphics{#5} & \includegraphics{#6}
		\end{tabular}
		\caption{#7.\label{#8}}
	\end{figure}
}

\newcommand{\ABS}[1]{\left|#1\right|}
\newcommand{\MATRIX}[2]{\PA{\begin{array}{#1}#2\end{array}}}
\newcommand{\PA}[1]{\left(#1\right)}

\bibliographystyle{abbrvnat}

\begin{document}

\title{MPCOTool (the Multi-Purposes Calibration and Optimization Tool): un
software libre para obtener parámetros empíricos necesarios en modelos de
simulación}

\author{Autores del software: J. Burguete y B. Latorre\\
Autor del manual: J. Burguete}

\maketitle

\tableofcontents

\chapter{Compilando el código fuente}

El código fuente en MPCOTool está escrito en lenguaje C. El programa ha sido
compilado y probado en los siguientes sistemas operativos:
\begin{itemize}
\item Debian Hurd, kFreeBSD y Linux 9;
\item Devuan Linux 2;
\item DragonFly BSD 5.2;
\item Dyson Illumos;
\item Fedora Linux 29;
\item FreeBSD 11.2;
\item Linux Mint DE 3;
\item Manjaro Linux;
\item Microsoft Windows 7\footnotemark[1], y 10\footnotemark[1];
\item NetBSD 7.0;
\item OpenBSD 6.4;
\item OpenIndiana Hipster;
\item OpenSUSE Linux Leap;
\item Ubuntu Mate Linux 18.04;
\item y Xubuntu Linux 18.10.
\end{itemize}
Es probable que también puede compilarse y funcione en otros sistemas
operativos, otras distribuciones de software y otras versiones pero no ha sido
probado.
\footnotetext[1]{Windows 7, y Windows 10 son marcas registradas de
Microsoft Corporation.}

Para generar el fichero ejecutable a partir de código fuente, un compilador de C
(\citet{gcc} o \citet{clang}), los sistemas de configuración \citet{autoconf},
\citet{automake} y \citet{pkgconfig}, el programa de control de la creación de
ejecutables \citet{gnumake} y las siguienres librerías de software libre son
necesarias:
\begin{itemize}
\item\citet{libxml}: Librería requerida para leer el fichero principal de
entrada en formato XML.
\item\citet{gsl}: Librería científica usada para generar los números
pseudo-aleatorios usados por los algoritmos genético y de Monte-Carlo.
\item\citet{glib}: Librería requerida para analizar las plantillas de los
ficheros de entrada y para implementar algunos tipos de datos, funciones útiles
y rutinas usadas para paralelizar la carga computacional en los diferentes
procesadores de la máquina.
\item\citet{json-glib}: Librería usada para leer el fichero principal de entrada
en formato JSON.
\item\citet{gtk}: Librería opcional usada para dibujar la interfaz gráfica
interactiva.
\item\citet{openmpi} o \citet{mpich}: Librerías opcionales. Cuando están
instaladas en el sistema una de ellas es usada para permitir la paralelización
del cálculo en múltiples computadoras.
\end{itemize}
Las indicaciones proporcionadas en \citet{install-unix} pueden seguirse para
instalar todas estas utilidades.

En OpenBSD 6.4, antes de generar el código, deben seleccionarse versiones
adecuadas de Autoconf y Automake haciendo en un terminal:
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
> export AUTOCONF_VERSION=2.69 AUTOMAKE_VERSION=1.16
\end{lstlisting}

En sistemas Windows hay que instalar MSYS2
(http://sourceforge.net/projects/msys2) y las librerías y utilidades requeridas.
Para ello se pueden seguir las instrucciones detalladas en
https://github.com/jburguete/install-unix.

En Fedora Linux 29, para usar OpenMPI hay que hacer en un terminal (en la
versión de 64 bits):
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
> export PATH=$PATH:/usr/lib64/openmpi/bin
\end{lstlisting}

En FreeBSD 11.2, debido a un extraño error en la versión por defecto de gcc, hay que hacer en un terminal:
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
> export CC=gcc5 (o CC=clang)
\end{lstlisting}

Una vez que todas las utilidades necesarias han sido instaladas, hay que
descargar el código de Genetic. Luego puede compilarse haciendo en un terminal:
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
> git clone https://github.com/jburguete/genetic.git
> cd genetic/2.2.2
> ./build
\end{lstlisting}

El siguiente paso es descargar el código fuente de MPCOTool, enlazarlo con el
de Genetic y compilar todo junto haciendo:
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
> git clone https://github.com/jburguete/mpcotool.git
> cd mpcotool/4.12.0
> ln -s ../../genetic/2.2.2 genetic
> ln -s genetic/libgenetic.so (o .dll en sistemas Windows)
> ./build
\end{lstlisting}

En sevidores o en clústers, en los que una versión sin interfaz gráfica
paralelizada con MPI es lo más conveniente, reemplácese el script \emph{build}
por:
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
> ./build_without_gui
\end{lstlisting}
 
Opcionalmente, si se quieren compilar los tests con las funciones analíticas de
optimización estándar, hay que hacer (los ejecutables de test2, test3 y test4
usan también la librería \emph{Genetic}):
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
> cd ../tests/test2
> ln -s ../../../genetic/2.2.2 genetic
> ln -s genetic/libgenetic.so (.dll en sistemas Windows)
> cd ../test3
> ln -s ../../../genetic/2.2.2 genetic
> ln -s genetic/libgenetic.so (.dll en sistemas Windows)
> cd ../test4
> ln -s ../../../genetic/2.2.2 genetic
> ln -s genetic/libgenetic.so (.dll en sistemas Windows)
> cd ../../4.12.0
> make tests
\end{lstlisting}

Finalmente podemos construir los manuales en formato PDF haciendo:
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
> make manuals
\end{lstlisting}

\chapter{Interfaz}

{\bf ¡OJO!} La representación de los números reales se hace, según el estándar
internacional, separando los decimales mediante el ``.'' decimal.

\section{Formato en línea de comandos}

En esta sección hemos marcado entre corchetes los argumentos opcionales.

\begin{itemize}

\item La línea de comandos en modo secuencial es (donde X es el número de hilos
a ejecutar paralelamente y S una semilla para el generador de números
pseudo-aleatorios):
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
> ./mpcotoolbin [-nthreads X] [-seed S] fichero_de_entrada.xml
[fichero_de_resultados] [fichero_de_variables]
\end{lstlisting}

\item La línea de comandos en modo paralelizado en diferentes computadoras con
MPI es (donde X es el número de hilos a ejecutar en cada nodo y S una semilla
para el generador de números pseudo-aleatorios):
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
> mpirun [MPI options] ./mpcotoolbin [-nthreads X] [-seed S] 
fichero_de_entrada.xml [fichero_de_resultados]
[fichero_de_variables]
\end{lstlisting}

\item La sintaxis del programa simulador ha de ser:
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
> ./simulador fichero_de_entrada_1 [fichero_de_entrada_2] [...]
fichero_de_salida
\end{lstlisting}
Hay dos opciones para el fichero de salida. Puede comenzar con un número que
indique el valor de la función objetivo o puede ser un fichero de resultados que
tiene que ser evaluado por un programa externo (el evaluador) comparando con un
fichero de datos experimentales.

\item En caso de la última opción del punto anterior, la sintaxis del programa
para evaluar la función objetivo tiene que ser (donde el fichero de resultados
debe comenzar con el valor de la función objetivo):
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
> ./evaluador fichero_simulado fichero_experimental
fichero_de_resultados
\end{lstlisting}

\item En systemas de tipo UNIX, la aplicación interactiva puede abrirse haciendo
en un terminal:
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
> ./mpcotool
\end{lstlisting}

\end{itemize}

\section{Uso de MPCOTool como una librería externa}

\emph{MPCOTool} se puede usar también como una librería externa haciendo:

\begin{enumerate}

\item Cópiese la librería dinámica (``libmpcotool.so'' en sistemas Unix o
``libmpcotool.dll'' en sistemas Windows) a la ruta de su programa.

\item Inclúyase la cabecera de la función en su código fuente:
\begin{lstlisting}[language=c,basicstyle=\scriptsize]
> extern int mpcotool (int argn, char **argc);
\end{lstlisting}

\item Constrúyase el fichero ejecutable de su programa incluyendo los flags del
enlazador:
\begin{lstlisting}[language=bash,basicstyle=\scriptsize]
> $ gcc ... -L. -Wl,-rpath=. -lmpcotool ...
\end{lstlisting}

\item La llamada a esta función es equivalente a la orden en modo de línea de
comandos (véase la sección anterior):
	\begin{itemize}
		\item argn: número de argumentos incluyendo el nombre del programa.
		\item argc$[0]$: "mpcotool" (nombre del programa).
		\item argc$[1]$: primer argumento de la línea de comandos.

	  ...

		\item argc$[argn-1]$: último argumento de la línea de comandos.
	\end{itemize}
\end{enumerate}

\section{Aplicación con interfaz gráfica de usuario interactiva}

Una forma alternativa de usar el programa consiste en usar la aplicación con
interfaz gráfica de usuario interactiva, llamada \emph{MPCOTool}. En esta
aplicación la paralelización en diferentes computadoras usando OpenMPI o MPICH
está desactivada, esta paralelización sólo puede usarse en modo de comandos. En
la figura~\ref{FigWindow} se muestra una figura con la ventana principal de la
utilidad. Desde esta ventana podemos acceder a cada variable, coeficiente,
algoritmo y programa de simulación requerido.
\begin{figure}[ht!]
	\centering
	\includegraphics[width=10.13cm]{mpcotool-es.eps}
	\caption{Ventana principal de la aplicación con interfaz gráfica de usuario
		interactiva de MPCOTool.\label{FigWindow}}
\end{figure}

Los resultados óptimos se presentan finalmente en un cuadro de diálogo como el
mostrado en la figura~\ref{FigResult}.
\begin{figure}[ht!]
	\centering
	\includegraphics[width=2.87cm]{result-es.eps}
	\caption{Cuadro de diálogo de los resultados óptimos de la aplicación con
		interfaz gráfica de usuario interactiva de MPCOTool.\label{FigResult}}
\end{figure}

\section{Ficheros de entrada}

\subsection{Fichero de entrada principal}

Este fichero puede escribirse en formato XML con una estructura arbórea como la
representada en la figura~\ref{FigMainFile}.
\psset{xunit=0.4mm,yunit=0.4mm}
\PSPICTURE{0}{-115}{280}{25}
{
	\tiny
	\psframe(0,-5)(280,25)
	\psline(40,-5)(40,25)
	\rput(20,20){\bf optimize}
	\rput(60,20){\bf simulator}
	\rput(95,20){\bf algorithm}
	\rput(130,20){evaluator}
	\rput(165,20){nsimulations}
	\rput(205,20){niterations}
	\rput(240,20){tolerance}
	\rput(265,20){nbest}
	\rput(60,10){threshold}
	\rput(95,10){npopulation}
	\rput(135,10){ngenerations}
	\rput(170,10){mutation}
	\rput(205,10){reproduction}
	\rput(240,10){adaptation}
	\rput(265,10){seed}
	\rput(60,0){climbing}
	\rput(95,0){nsteps}
	\rput(130,0){nestimates}
	\rput(170,0){relaxation}
	\rput(200,0){norm}
	\rput(217,0){p}
	\rput(235,0){result}
	\rput(260,0){variables}
	\psline(20,-5)(20,-15)(40,-15)
	\psframe(40,-20)(280,-10)
	\psline(80,-20)(80,-10)
	\rput(60,-15){\bf experiment}
	\rput(95,-15){\bf name}
	\rput(125, -15){\bf template$_\mathbf{1}$}
	\rput(160,-15){template$_2$}
	\rput(195,-15){$\cdots$}
	\rput(230,-15){template$_n$}
	\rput(260,-15){weight}
	\psline(20,-15)(20,-25)
	\rput(140,-30){$\cdots$}
	\psline(20,-35)(20,-45)(40,-45)
	\psframe(40,-50)(280,-40)
	\psline(80,-50)(80,-40)
	\rput(60,-45){\bf experiment}
	\rput(95,-45){\bf name}
	\rput(125,-45){\bf template$_\mathbf{1}$}
	\rput(160,-45){template$_2$}
	\rput(195,-45){$\cdots$}
	\rput(230,-45){template$_n$}
	\rput(260,-45){weight}
	\psline(20,-45)(20,-65)(40,-65)
	\psframe(40,-75)(280,-55)
	\psline(80,-75)(80,-55)
	\rput(60,-60){\bf variable}
	\rput(95,-60){\bf name}
	\rput(120,-60){\bf minimum}
	\rput(152.5,-60){\bf maximum}
	\rput(195,-60){absolute\_minimum}
	\rput(250,-60){absolute\_maximum}
	\rput(100,-70){precision}
	\rput(130,-70){nsweeps}
	\rput(155,-70){nbits}
	\rput(175,-70){step}
	\psline(20,-65)(20,-80)
	\rput(140,-85){$\cdots$}
	\psline(20,-90)(20,-105)(40,-105)
	\psframe(40,-115)(280,-95)
	\psline(80,-115)(80,-95)
	\rput(60,-100){\bf variable}
	\rput(95,-100){\bf name}
	\rput(120,-100){\bf minimum}
	\rput(152.5,-100){\bf maximum}
	\rput(195,-100){absolute\_minimum}
	\rput(250,-100){absolute\_maximum}
	\rput(100,-110){precision}
	\rput(130,-110){nsweeps}
	\rput(155,-110){nbits}
	\rput(175,-110){step}
}{Estructura del fichero principal de entrada. Nodos y propiedades
imprescindibles están en negrita. No obstante, otras propiedades también pueden
ser necesarias en función del algoritmo de optimización seleccionado}
{FigMainFile}

El nodo XML principal tiene que comenzar con la etiqueta ``\emph{optimize}''.
Las propiedades que se pueden definir son:
\begin{description}
	\item[simulator]: indica el programa simulador.
	\item[evaluator]: opcional. Especifica el programa de evaluación en caso de
		ser requerido.
	\item[algorithm]: fija el algoritmo de optimización. Actualmente tres
		métodos están disponibles:
	\begin{description}
		\item[sweep]: algoritmo de fuerza bruta de barrido regular. Requiere 
			definir en cada variable:
			\begin{description}
				\item[nsweeps]: número de barridos para la variable en cada
					experimento.
			\end{description}
		\item[Monte-Carlo]: algoritmo de fuerza bruta de Monte-Carlo. Requiere
			definir en el nodo XML principal:
			\begin{description}
				\item[nsimulations]: número de simulaciones a ejecutar en cada
					iteración y en cada experimento.
			\end{description}
		\item[genetic]: algoritmo genético. Necesita definir los siguientes
			parámetros en el nodo XML principal:
			\begin{description}
				\item[npopulation]: número de individuos de la población.
				\item[ngenerations]: número de generaciones.
				\item[mutation]: ratio de mutación.
				\item[reproduction]: ratio de reproducción.
				\item[adaptation]: ratio de adaptación.
			\end{description}
			Además para cada variable:
			\begin{description}
				\item[nbits]: número de bits para codificar la variable.
			\end{description}
		\item[orthogonal]: algoritmo de fuerza bruta de muestreo ortogonal. 
			Requiere definir en cada variable:
			\begin{description}
				\item[nsweeps]: número de barridos para la variable en cada
					experimento.
			\end{description}
	\end{description}
	\item[niterations]: número de iteraciones (valor por defecto: 1) para
		realizar el algoritmo iterativo,
	\item[nbest]: número de mejores simulaciones con las que calcular el
		siguiente intervalo de convergencia en la siguiente iteración del
		algoritmo iterativo (valor por defecto: 1),
	\item[tolerance]: parámetro de tolerancia para relajar el intervalo de
		convergencia del algoritmo iterativo (valor por defecto: 0),
	\item[threshold]: umbral en la función objetivo para detener la
		optimización,
	\item[seed]: semilla del generador de números pseudo-aleatorios (valor por
		defecto 7007),
	\item[climbing]: método de ascenso (opcional para los algoritmos de fuerza
		bruta). Dos valores están disponibles actualmente:
	\begin{description}
		\item[coordinates]: ascenso por coordenadas,
		\item[random]: ascenso aleatorio. Requiere:
		\begin{description}
			\item[nestimates]: número de pruebas aleatorias para buscar el
				ascenso óptimo.
		\end{description}
	\end{description}
	Ambos métodos requieren además los siguientes parámetros:
	\begin{description}
		\item[nsteps]: número de pasos para ejecutar el método de ascenso de
			colinas,
		\item[relaxation]: parámetro de relajación para el método de ascenso de
			colinas,
	\end{description}
	y para cada variable:
	\begin{description}
		\item[step]: tamaño de paso inicial para el método de ascenso de
			colinas,
	\end{description}
	\item[norm]: selecciona la norma de error (valor por defecto:
		``euclidian''). Actualmente se pueden escoger cuatro tipos:
		\begin{description}
			\item[euclidian]: norma de error euclidiana $L_2$, véase
				(\ref{EqObjectiveFunctionLII}),
			\item[maximum]: norma de error máximo $L_\infty$, véase
				(\ref{EqObjectiveFunctionLi}),
			\item[p]: norma de error P $L_p$. Requiere:
			\begin{description}
				\item[p]: exponente de la norma de error P, véase
					(\ref{EqObjectiveFunctionLp}),
			\end{description}
			\item[taxicab]: norma de error taxicab $L_1$, véase
				(\ref{EqObjectiveFunctionLI}),
		\end{description}
	\item[result]: define el nombre del fichero de resultados óptimos. Es
		opcional, si no se especifica se guarda con el nombre ``\emph{result}'';
	\item[variables]: define el nombre del fichero donde se guardan todas
		las combinaciones de variables simuladas. Es opcional, si no se
		especifica se guarda con el nombre ``\emph{variables}''.
\end{description}

El primer tipo de nodos XML hijos tiene que comenzar con la etiqueta
``\emph{experiment}''. Especifica los datos experimentales. Contiene las
propiedades:
\begin{description}
	\item[name]: nombre del fichero de datos experimentales a calibrar.
	\item[templateX]: $X$-ésima plantilla del fichero de datos experimentales
		del programa de simulación.
	\item[weight]: peso (valor por defecto: 1) para aplicar en la función
		objetivo (véase (\ref{EqObjectiveFunctionLII}) a
		(\ref{EqObjectiveFunctionLI})).
\end{description}

El segundo tipo de nodos XML hijo tiene que comenzar con la etiqueta
\emph{variable}''. En estos nodos se especifican los datos de las variables que
se definen con las propiedades siguientes:
\begin{description}
	\item[name]: etiqueta de la variable. Para la variable $X$-ésima, se
		analizan todas las plantillas de entrada y se crean ficheros de entrada
		correspondientes para el programa simulador reemplazando todas las
		etiquetas con el formato @variableX@ por el contenido de esta propiedad.
\item[minimum, maximum]: rango de valores de las variables. El programa crea los
	ficheros de entrada de la simulación reemplazando todas las etiquetas
	@valueX@ de las plantillas de entrada por un valor en este rango para la
	vairable $X$-ésima, calculado por el algoritmo de optimización.
\item[absolute\_minimum, absolute\_maximum]: rango de valores permitido. En
	métodos iterativos, la tolerancia puede incrementar el rango inicial de
	valores en cada iteración. Estos valores son el rango permitido para las
	variables compatible con los límites del modelo.
\item[precision]: número de dígitos decimales de precisión. 0 se aplica a los
	números enteros.
\end{description}

En este formato el fichero sería de la forma:
\begin{lstlisting}[language=xml,basicstyle=\scriptsize]
<?xml version="1.0"?>
<optimize simulator="simulator_name" evaluator="evaluator_name"
	algorithm="algorithm_type" nsimulations="simulations_number"
	niterations="iterations_number" tolerance="tolerance_value"
	nbest="best_number" npopulation="population_number"
	ngenerations="generations_number" mutation="mutation_ratio"
	reproduction="reproduction_ratio" adaptation="adaptation_ratio"
	climbing="hill_climbing_type" nsteps="steps_number"
	relaxation="relaxation_parameter" nestimates="estimates_number"
	threshold="threshold_parameter" norm="norm_type" p="p_parameter"
	seed="random_seed" result_file="result_file"
	variables_file="variables_file">
    <experiment name="data_file_1" template1="template_1_1"
		template2="template_1_2" ... weight="weight_1"/>
    ...
    <experiment name="data_file_N" template1="template_N_1"
		template2="template_N_2" ... weight="weight_N"/>
    <variable name="variable_1" minimum="min_value" maximum="max_value"
		precision="precision_digits" sweeps="sweeps_number"
		nbits="bits_number" step="step_size"/>
    ...
    <variable name="variable_M" minimum="min_value" maximum="max_value"
		precision="precision_digits" sweeps="sweeps_number"
		nbits="bits_number" step="step_size"/>
</optimize>
\end{lstlisting}

Alternativamete, este fichero también puede escribirse en formato JSON:
\begin{lstlisting}[language=json,basicstyle=\scriptsize]
{
	"simulator": "simulator_name",
	"evaluator": "evaluator_name",
	"algorithm": "algorithm_type",
	"nsimulations": "simulations_number",
	"niterations": "iterations_number",
	"tolerance": "tolerance_value",
	"nbest": "best_number",
	"npopulation": "population_number",
	"ngenerations": "generations_number",
	"mutation": "mutation_ratio",
	"reproduction": "reproduction_ratio",
	"adaptation": "adaptation_ratio",
	"climbing": "hill_climbing_type",
	"nsteps": "steps_number",
	"relaxation": "relaxation_parameter",
	"nestimates": "estimates_number",
	"threshold": "threshold_parameter",
	"norm": "norm_type",
	"p": "p_parameter",
	"seed": "random_seed",
	"result_file": "result_file",
	"variables_file": "variables_file",
	"experiments":
	[
		{
			"name": "data_file_1",
			"template1": "template_1_1",
			"template2": "template_1_2",
			...
			"weight": "weight_1",
		},
	    ...
		{
			"name": "data_file_N",
			"template1": "template_N_1",
			"template2": "template_N_2",
			...
			"weight": "weight_N",
		}
	],
	"variables":
	[
		{

			"name": "variable_1",
			"minimum": "min_value",
			"maximum": "max_value",
			"precision": "precision_digits",
			"sweeps": "sweeps_number",
			"nbits": "bits_number",
			"step": "step_size",
		},
		...
		{
			"name": "variable_M",
			"minimum": "min_value",
			"maximum": "max_value",
			"precision": "precision_digits",
			"sweeps": "sweeps_number",
			"nbits": "bits_number",
			"step": "step_size",
		}
	]
}
\end{lstlisting}

\subsection{Ficheros de plantilla}

Hay que generar $N_{experimentos}\times N_{entradas}$ ficheros de plantilla para
reproducir cada fichero de entrada asociado a cada uno de los experimentos
(véase la figura~\ref{FigStructure}). Todos estos ficheros de plantilla son
analizados sintáctimente por MPCOTool reemplazándose las siguientes etiquetas
clave para generar los ficheros de entrada del programa simulador:
\begin{description}
\item[@variableX@]: se reemplaza por la etiqueta asociada al $X$-ésima parámetro
	empírico definido en el fichero principal de entrada.
\item[@valueX@]: se reemplaza por el valor asociado al $X$-ésima parámetro
	empírico calculado por el algoritmo de optimización usando los datos
	definidos en el fichero principal de entrada.
\end{description}

\section{Ficheros de salida}

\subsection{Fichero de resultados}

MPCOTool genera un fichero donde se guarda la mejor combinación de variables y
su correspondiente función objetivo calculada así como el tiempo de cálculo. El
nombre de este fichero puede definirse en la propiedad \emph{result} del fichero
de entrada principal. Si no se define se crea un fichero de nombre ``result''.

\subsection{Fichero de variables}

El programa genera también un fichero donde se guardan en columnas cada una de
las combinaciones de variables probadas en la calibración, siendo además la
última columna el valor de la función objetivo. El nombre de este fichero puede
definirse en la propiedad \emph{variables}. Si no se especifica esta propiedad
se crea un fichero de numbre ``variables''.

\chapter{Organización de MPCOTool}

Supongamos que buscamos un conjunto de $N_{parameters}$ parámetros empíricos 
requeridos por un modelo de simulación que sea el que mejor ajuste el conjunto
de $N_{experimentos}$ datos experimentales y que el programa simulador requiere
además $N_{entradas}$ ficheros de entrada.
La estructura seguida por MPCOTool se resume en el \emph{fichero de entrada
principal}, donde se especifican tanto $N_{experimentos}$ como $N_{entradas}$.
También contiene los valores extremos de los parámetros empíricos y el algoritmo
de optimización escogido. Entonces MPCOTool lee las corespondientes
$N_{experimentos}\times N_{entradas}$ plantillas para crear los ficheros de
entrada del simulador reemplazando etiquetas clave por los parámetros empíricos
generados por el algoritmo de optimización. Hay dos opciones: o bien el programa
simulador compara directamente los resultados de la simulación con el
\emph{fichero de datos experimentales} y genera un fichero con el valor de la
función objetivo; o bien otro programa externo, definido en la propiedad
\emph{evaluator}, es ejecutado para comparar con el \emph{fichero de datos
experimentales} produciendo el valor de la función objetivo. En ambos casos el
valor de la función objetivo se guarda en un \emph{fichero de valores
objetivos}. Por lo tanto, para cada experimento se obtiene un valor objetivo
$o_i$. El valor final de la función objetivo ($J$) asociado al conjunto de
experimentos puede calcularse de cuatro modos:
\EQ{L_2:\quad J=\sqrt{\sum_{i=1}^{N_{experiments}}\ABS{w_i\,o_i}^2},}
{EqObjectiveFunctionLII}
\EQ{L_\infty:\quad J=\max_{i=1}^{N_{experiments}}\ABS{w_i\,o_i},}
{EqObjectiveFunctionLi}
\EQ{L_p:\quad J=\sqrt[p]{\sum_{i=1}^{N_{experiments}}\ABS{w_i\,o_i}^p},}
{EqObjectiveFunctionLp}
\EQ{L_1:\quad J=\sum_{i=1}^{N_{experiments}}\ABS{w_i\,o_i},}
{EqObjectiveFunctionLI}
con $w_i$ el peso asociado al experimento $i$-ésimo, que se especifica en el
\emph{fichero de entrada principal}. En la figura~\ref{FigStructure} puede verse
un esquema de la estructura.
\psset{xunit=0.4mm,yunit=0.4mm}
\PSPICTURE{-20}{-115}{260}{55}
{
	\tiny
	\rput(10,50){Entrada principal}
	\psframe(-20,45)(40,55)
	\psline{->}(40,50)(50,50)
	\rput(10,25){Plantilla primera}
	\psframe(-20,20)(40,30)
	\psline{->}(40,25)(50,25)
	\psline[linestyle=dotted,dotsep=1pt]{->}(50,25)(90,25)
	\rput(10,15){$\cdots$}
	\rput(10,5){Plantilla $n$-ésima}
	\psframe(-20,0)(40,10)
	\psline{->}(40,5)(50,5)
	\psline[linestyle=dotted,dotsep=1pt]{->}(50,5)(90,5)
	\rput(10,-35){$\cdots$}
	\rput(10,-75){Plantilla $(N\,n)$-ésima}
	\psframe(-20,-70)(40,-80)
	\psline{->}(40,-75)(50,-75)
	\psline[linestyle=dotted,dotsep=1pt]{->}(50,-75)(90,-75)
	\rput(70,50){MPCOTool}
	\psframe(50,-95)(90,55)
	\rput(70,-110){Función objetivo}
	\psframe(35,-105)(105,-115)
	\psline{->}(70,-95)(70,-105)
	\psline{->}(90,25)(100,25)
	\psline{->}(90,5)(100,5)
	\psline{->}(90,-55)(100,-55)
	\psline{->}(90,-75)(100,-75)
	\rput(125,5){Entrada $n$-ésima}
	\psframe(100,0)(150,10)
	\psline{->}(150,5)(160,5)
	\rput(125,15){$\cdots$}
	\rput(125,25){Entrada primera}
	\psframe(100,20)(150,30)
	\psline{->}(150,25)(155,25)(155,5)
	\rput(180,5){Simulador}
	\psframe(160,0)(200,10)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(175,10)(175,20)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(200,5)(210,7.5)
	\rput(180,25){Resultados}
	\psframe[linestyle=dashed,dash=3pt 1pt](160,20)(200,30)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(200,25)(210,30)
	\rput(180,45){Datos del}
	\rput(180,40){experimento}
	\psframe(160,35)(200,50)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(200,42.5)(210,30)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(160,42.5)(155,42.5)(155,25)
	\rput(230,30){Evaluador}
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(230,25)(230,15)
	\psframe[linestyle=dashed,dash=3pt 1pt](210,25)(250,35)
	\rput(230,10){Valor}
	\rput(230,5){objetivo}
	\psframe(210,0)(250,15)
	\psline{->}(250,7.5)(260,7.5)(260,-90)(90,-90)
	\psline[linestyle=dotted,dotsep=1pt]{->}(90,-90)(70,-90)(70,-95)
	\rput(125,50){Experimento primero}
	\psframe[linestyle=dotted](95,-5)(255,55)
	\rput(175,-15){$\cdots$}
	\rput(125,-75){Entrada $n$-ésima}
	\psframe(100,-80)(150,-70)
	\psline{->}(150,-75)(160,-75)
	\rput(125,-65){$\cdots$}
	\rput(125,-55){Entrada primera}
	\psframe(100,-60)(150,-50)
	\psline{->}(150,-55)(155,-55)(155,-75)
	\rput(180,-75){Simulador}
	\psframe(160,-80)(200,-70)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(180,-70)(180,-60)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(200,-75)(210,-72.5)
	\rput(180,-55){Resultados}
	\psframe[linestyle=dashed,dash=3pt 1pt](160,-60)(200,-50)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(200,-55)(210,-50)
	\rput(180,-35){Datos del}
	\rput(180,-40){experimento}
	\psframe(160,-30)(200,-45)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(200,-37.5)(210,-50)
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(160,-37.5)(155,-37.5)(155,-55)
	\rput(230,-50){Evaluador}
	\psline[linestyle=dashed,dash=2pt 1pt]{->}(230,-55)(230,-65)
	\psframe[linestyle=dashed,dash=3pt 1pt](210,-55)(250,-45)
	\rput(230,-70){Valor}
	\rput(230,-75){objetivo}
	\psframe(210,-80)(250,-65)
	\psline(250,-72.5)(260,-72.5)
	\rput(125,-30){Experimento $N$-ésimo}
	\psframe[linestyle=dotted](95,-85)(255,-25)
}{Diagrama de flujo de las interacciones entre MPCOTool, los diferentes ficheros
de entrada y los programas de simulación y, en su caso, evaluación para producir
el valor de la función objetivo para cada combinación de parámetros empíricos
generada por el algoritmo de optimización}{FigStructure}

El proceso completo se repite para cada combinación de parámetros empíricos
generada por el algoritmo de optimización. Además, MPCOTool puede paralelizar
automáticamente las simulaciones usando todos los recursos de computación
disponibles en el sistema.

\chapter{Métodos de optimización}

A continuación se presentan los métodos de optimización implementados en
MPCOTool. Se usará la siguiente notación:
\begin{description}
	\item[$N_{simulaciones}$]: número de simulaciones en cada iteración,
	\item[$N_{iteraciones}$]: número de iteraciones en algoritmos iterativos,
	\item[$N_{total}$]: número total de simulaciones.
\end{description}
En métodos iterativos $N_{total}=N_{simulaciones}\times N_{iteraciones}$.
En métodos de fuerza bruta puros
$N_{iteraciones}=1\;\Rightarrow\;N_{total}=N_{simulaciones}$.

\section{Método de fuerza bruta de barrido regular}

El método de barrido regular es un método de fuerza bruta que encuentra el 
conjunto óptimo de parámatros en una región dividiéndola en subdominios 
regulares. Para encontrar la solución óptima, el intervalo de dominio
$x_i \in \PA{x_{i,min},\,x_{i,max}}$ se define para cada variable $x_i$.
y se subdivide en una partición regular de $N_{x,i}$ subintervalos. El número de
simulaciones que se requieren es:
\EQ{N_{simulaciones}=N_{x,1}\times N_{x,2}\times\cdots,}
{EqNSweeps}
donde $N_{x,i}$ es el número de barridos en la variable $x_i$.

En la figura~\ref{FigSweep} el dominio $(x,y)$ se define en los intervalos
$x\in\PA{x_{min},\,x_{max}}$ e $y \in \PA{y_{min},\,y_{max}}$. Ambos intervalos
$x$ e $y$ se dividen en 5 regiones con $N_{x}=N_{y}=5$. El parámetro óptimo se
encuentra evaluando el error de cada combinación de parámetros $\PA{x_i,\,y_i}$
requiriendo por tanto 25 evaluaciones. Nótese que el costo computacional se
incrementa exponencialmente con el número de variables.

\PICTURE{210}{200}
{
	\put(20,10){\vector(0,1){180}}
	\put(20,10){\vector(1,0){180}}
	\put(10,190){$y$}
	\put(200,0){$x$}
	\multiput(50,40)(30,0){5}{\qbezier[40](0,0)(0,60)(0,120)}
	\multiput(50,40)(0,30){5}{\qbezier[40](0,0)(60,0)(120,0)}
	\multiput(50,40)(30,0){5}{\multiput(0,0)(0,30){5}{\circle*{2}}}
	\qbezier[10](50,10)(50,25)(50,40)
	\put(40,0){$x_{\min}$}
	\qbezier[10](170,10)(170,25)(170,40)
	\put(160,0){$x_{\max}$}
	\qbezier[10](20,40)(35,40)(50,40)
	\put(0,37){$y_{\min}$}
	\qbezier[10](20,160)(35,160)(50,160)
	\put(0,157){$y_{\max}$}
}{Diagrama ilustrando un ejempo de aplicación del método de fuerza bruta de
barrido regular con dos variables para $N_x=N_y=5$}{FigSweep}

Los algoritmos de fuerza bruta presentan bajos ratios de convergencia pero son
fuertemente paralelizables debido a que cada simulación es completamente
independiente. Si la computadora, o el clúster de computadoras, puede ejecutar
$N_{tareas}$ tareas paralelizadas cada tarea efectúa $N_{total}/N_{tareas}$
simulaciones, obviamente teniendo en cuenta efectos de redondeo puesto que cada
tarea debe realizar un número natural de simulaciones. En la
figura~\ref{FigBruteForceParallelization} se presenta un diagrama de flujo del
esquema de esta paralelización. Puesto que cada tarea es independiente, una
distribución en las diferentes tareas permite explotar al máximo las
capacidades computacionales de la máquina en la que se ejecuta MPCOTool.

\psset{xunit=0.5mm,yunit=0.5mm}
\PSPICTURE{-90}{-55}{90}{-15}
{
	\tiny
	\rput(0,-15){Generación de $N_{total}$ conjuntos de parámetros empíricos}
	\psframe(-65,-20)(65,-10)
	\psline{->}(0,-20)(-50,-25)
	\psline{->}(0,-20)(0,-25)
	\psline{->}(0,-20)(55,-25)
	\rput(-55,-30){1$^a$ tarea:}
	\rput(-55,-35){$N_{total}/N_{tareas}$ simulaciones}
	\psframe(-90,-25)(-20,-40)
	\rput(0,-32.5){$\cdots$}
	\rput(55,-30){$N_{tareas}$-ésima tarea:}
	\rput(55,-35){$N_{total}/N_{tareas}$ simulaciones}
	\psframe(20,-25)(90,-40)
	\psline{->}(-55,-40)(0,-45)
	\psline{->}(0,-40)(0,-45)
	\psline{->}(55,-40)(0,-45)
	\rput(0,-50){Obtención del conjunto óptimo de parámetros empíricos}
	\psframe(-65,-45)(65,-55)
}{Diagrama de flujo del esquema de la paralelización en MPCOTool para métodos de
fuerza bruta (barrido regular, muestreo ortogonal y Monte-Carlo)}
{FigBruteForceParallelization}

\section{Método de Monte-Carlo}

Los métodos de Monte-Carlo realizan las simulaciones usando valores aleatorios
de las varaibles suponiendo una probabilidad uniforme dentro de un intervalo
permitido de valores. En la figura~\ref{FigMonteCarlo} se muestra la estructura
de un ejemplo usando dos variables.

\PICTURE{210}{200}
{
	\put(20,10){\vector(0,1){180}}
	\put(20,10){\vector(1,0){180}}
	\put(10,190){$y$}
	\put(200,0){$x$}
	\put(69,159){\circle*{2}}
	\put(163,73){\circle*{2}}
	\put(108,67){\circle*{2}}
	\put(139,154){\circle*{2}}
	\put(138,104){\circle*{2}}
	\put(129,131){\circle*{2}}
	\put(146,77){\circle*{2}}
	\put(70,102){\circle*{2}}
	\put(97,97){\circle*{2}}
	\put(75,66){\circle*{2}}
	\put(90,43){\circle*{2}}
	\put(163,63){\circle*{2}}
	\put(157,109){\circle*{2}}
	\put(109,119){\circle*{2}}
	\put(71,107){\circle*{2}}
	\put(64,75){\circle*{2}}
	\put(127,47){\circle*{2}}
	\put(126,127){\circle*{2}}
	\put(61,125){\circle*{2}}
	\put(62,123){\circle*{2}}
	\put(110,55){\circle*{2}}
	\put(84,64){\circle*{2}}
	\put(65,49){\circle*{2}}
	\put(59,105){\circle*{2}}
	\put(156,75){\circle*{2}}	
	\qbezier[50](50,10)(50,85)(50,160)
	\put(40,0){$x_{\min}$}
	\qbezier[50](170,10)(170,85)(170,160)
	\put(160,0){$x_{\max}$}
	\qbezier[50](20,40)(95,40)(170,40)
	\put(0,37){$y_{\min}$}
	\qbezier[50](20,160)(95,160)(170,160)
	\put(0,157){$y_{\max}$}
}{Diagrama illustrativo de un método de fuerza bruta de Monte-Carlo con dos
variables and $N_{simulaciones}=25$}{FigMonteCarlo}

El método de Monte-Carlo es también fácilmente paralelizable siguiendo una
estrategia como la del diagrama de flujo representado en la
figura~\ref{FigBruteForceParallelization}.

\section{Método de fuerza bruta de muestreo ortogonal}

El método de muestreo ortogonal es un método de fuerza bruta que trata de
conjugar lo mejor de los métodos de barrido regular y Monte-Carlo. Se subdivide
el dominio de parámatros en subdominios regulares y se aplica el método de
Monte-Carlo en cada uno de estos subdominios. Entonces, el intervalo de dominio
$x_i \in \PA{x_{i,min},\,x_{i,max}}$ se define para cada variable $x_i$.
y se subdivide en una partición regular de $N_{x,i}$ subintervalos. El número de
simulaciones que se requieren es:
\EQ{N_{simulaciones}=N_{x,1}\times N_{x,2}\times\cdots,}
{EqNSweeps}
donde $N_{x,i}$ es el número de barridos en la variable $x_i$.

En la figura~\ref{FigSweep} el dominio $(x,y)$ se define en los intervalos
$x\in\PA{x_{min},\,x_{max}}$ e $y \in \PA{y_{min},\,y_{max}}$. Ambos intervalos
$x$ e $y$ se dividen en 5 regiones con $N_{x}=N_{y}=5$. El parámetro óptimo se
encuentra evaluando el error de cada combinación de parámetros $\PA{x_i,\,y_i}$
requiriendo por tanto 25 evaluaciones. Nótese que el costo computacional se
incrementa exponencialmente con el número de variables como en el método de
barrido regular.

\PICTURE{210}{200}
{
	\put(20,10){\vector(0,1){180}}
	\put(20,10){\vector(1,0){180}}
	\put(10,190){$y$}
	\put(200,0){$x$}
	\multiput(50,40)(30,0){5}{\qbezier[40](0,0)(0,60)(0,120)}
	\multiput(50,40)(0,30){5}{\qbezier[40](0,0)(60,0)(120,0)}
	\multiput(50,40)(30,0){5}{\multiput(0,0)(0,30){5}{\circle*{2}}}
	\qbezier[10](50,10)(50,25)(50,40)
	\put(40,0){$x_{\min}$}
	\qbezier[10](170,10)(170,25)(170,40)
	\put(160,0){$x_{\max}$}
	\qbezier[10](20,40)(35,40)(50,40)
	\put(0,37){$y_{\min}$}
	\qbezier[10](20,160)(35,160)(50,160)
	\put(0,157){$y_{\max}$}
}{Diagrama ilustrando un ejempo de aplicación del método de fuerza bruta de
barrido regular con dos variables para $N_x=N_y=5$}{FigOrthogonal}

Los algoritmos de fuerza bruta presentan bajos ratios de convergencia pero son
fuertemente paralelizables debido a que cada simulación es completamente
independiente. Si la computadora, o el clúster de computadoras, puede ejecutar
$N_{tareas}$ tareas paralelizadas cada tarea efectúa $N_{total}/N_{tareas}$
simulaciones, obviamente teniendo en cuenta efectos de redondeo puesto que cada
tarea debe realizar un número natural de simulaciones. En la
figura~\ref{FigBruteForceParallelization} se presenta un diagrama de flujo del
esquema de esta paralelización. Puesto que cada tarea es independiente, una
distribución en las diferentes tareas permite explotar al máximo las
capacidades computacionales de la máquina en la que se ejecuta MPCOTool.

\section{Algoritmo iterativo aplicado a los métodos de fuerza bruta}

MPCOTool permite iterar los métodos de fuerza bruta, Monte-Carlo, muestreo
ortogonal o barrido regular, para mejorar la convergencia. En este algoritmo se
seleccionan un conjunto de $N_{best}^j$ mejores resultados en cada iteración
$j$-ésima y se usan para forzar nuevos intervalos para la búsqueda de valores
óptimos en la siguiente iteración. Definiendo:
\begin{description}
\item[$\displaystyle x_{\max}^b=\max_{i\in N_{best}}x_i^j$]: Valor máximo de la
	variable $x$ en el subconjunto de $N_{best}^j$ mejores resultados de la
	iteración $j$-ésima.
\item[$\displaystyle x_{\min}^b=\max_{i\in N_{best}}x_i^j$]: Valor mínimo de la
	variable $x$ en el subconjunto de $N_{best}^j$ mejores resultados de la
	iteración $j$-ésima.
\end{description}
Entonces se usará el nuevo intervalo para la variable $x$ para buscar valores
óptimos en la siguiente $(j+1)$-ésima iteración:
\EQ{x_i^{j+1}\in\left[x_{\min}^{j+1},\;x_{\max}^{j+1}\right],}
{EqIterationInterval}
con:
\[
	\mathrm{Barrido\,o\,muestreo\,ortogonal}\;\Rightarrow\;
	\left\{\begin{array}{c}\displaystyle
	x_{\max}^{j+1}=x_{\max}^b+\frac{x_{\max}^j-x_{\min}^j}{N_x-1}\,tolerance,\\
	\displaystyle
	x_{\min}^{j+1}=x_{\min}^b-\frac{x_{\min}^j-x_{\min}^j}{N_x-1}\,tolerance,\\
	\end{array}\right.
\]
\EQ
{
	\mathrm{Monte-Carlo}\;\Rightarrow\;\left\{\begin{array}{c}
	\displaystyle x_{\max}^{j+1}=\frac{x_{\max}^b+x_{\min}^b
	+\left(x_{\max}^b-x_{\min}^b\right)(1+tolerance)}{2},\\
	\displaystyle x_{\min}^{j+1}=\frac{x_{\max}^b+x_{\min}^b
	-\left(x_{\max}^b-x_{\min}^b\right)(1+tolerance)}{2},
	\end{array}\right.
}{EqIterationIntervalII}
siendo $tolerance$ un factor que incremente el tamaño del intervalo de variables
a simular en la siguiente iteración.
En la figura~\ref{FigIterative} se muestra un esquema del procedimiento que usa
el algoritmo iterativo para modificar los intervalos de variables para mejorar
la convergencia.

\PICTURE{210}{400}
{
	\small
	\multiput(0,0)(0,200){2}
	{
		\put(20,10){\vector(0,1){180}}
		\put(20,10){\vector(1,0){180}}
		\put(10,190){$y$}
		\put(200,0){$x$}
	}
	\put(90,380){1ª iteración}
	\put(50,370){*: mejores resultados}
	\put(69,359){\circle*{2}}
	\put(163,273){\circle*{2}}
	\put(108,267){*}
	\put(139,354){\circle*{2}}
	\put(138,304){*}
	\put(129,331){\circle*{2}}
	\put(146,277){\circle*{2}}
	\put(70,302){\circle*{2}}
	\put(97,297){*}
	\put(75,266){\circle*{2}}
	\put(90,243){\circle*{2}}
	\put(163,263){\circle*{2}}
	\put(157,309){\circle*{2}}
	\put(109,319){*}
	\put(71,307){\circle*{2}}
	\put(64,275){\circle*{2}}
	\put(127,247){\circle*{2}}
	\put(126,327){\circle*{2}}
	\put(61,325){\circle*{2}}
	\put(62,323){\circle*{2}}
	\put(110,255){\circle*{2}}
	\put(84,264){\circle*{2}}
	\put(65,249){\circle*{2}}
	\put(59,305){\circle*{2}}
	\put(156,275){\circle*{2}}	
	\qbezier[50](50,210)(50,285)(50,360)
	\put(40,200){$x_{\min}^1$}
	\qbezier[50](170,210)(170,285)(170,360)
	\put(160,200){$x_{\max}^1$}
	\qbezier[50](20,240)(95,240)(170,240)
	\put(0,237){$y_{\min}^1$}
	\qbezier[50](20,360)(95,360)(170,360)
	\put(0,357){$y_{\max}^1$}
	\qbezier[21](99,272)(119.5,272)(140,272)
	\qbezier[21](99,324)(119.5,324)(140,324)
	\qbezier[26](99,272)(99,298)(99,324)
	\qbezier[26](140,272)(140,298)(140,324)
	\put(99,267){\vector(1,0){41}}
	\put(140,267){\vector(-1,0){41}}
	\put(95,255){$x_{\max}^b-x_{\min}^b$}
	\put(94.9,215){\vector(1,0){49.2}}
	\put(144.1,215){\vector(-1,0){49.2}}
	\put(95,220){$x_{\max}^2-x_{\min}^2$}
	\qbezier[20](99,272)(96.95,241)(94.9,210)
	\qbezier[20](140,272)(142.05,241)(144.1,210)
	\qbezier[26](99,272)(69.5,269.4)(20,266.8)
	\qbezier[26](99,324)(69.5,326.6)(20,329.2)
	\put(80,180){2ª iteración}
	\put(102,123){\circle*{2}}
	\put(141,83){\circle*{2}}
	\put(118,80){\circle*{2}}
	\put(131,121){\circle*{2}}
	\put(131,97){\circle*{2}}
	\put(127,110){\circle*{2}}
	\put(134,84){\circle*{2}}
	\put(103,96){\circle*{2}}
	\put(114,94){\circle*{2}}
	\put(105,79){\circle*{2}}
	\put(111,68){\circle*{2}}
	\put(141,78){\circle*{2}}
	\put(139,100){\circle*{2}}
	\put(119,104){\circle*{2}}
	\put(103,98){\circle*{2}}
	\put(100,83){\circle*{2}}
	\put(126,70){\circle*{2}}
	\put(126,108){\circle*{2}}
	\put(99,107){\circle*{2}}
	\put(100,106){\circle*{2}}
	\put(119,74){\circle*{2}}
	\put(109,78){\circle*{2}}
	\put(101,71){\circle*{2}}
	\put(99,98){\circle*{2}}
	\put(138,83){\circle*{2}}
	\qbezier[40](94.9,10)(94.9,69.6)(94.9,129.2)
	\put(84.9,0){$x_{\min}^2$}
	\qbezier[40](144.1,10)(144.1,69.6)(144.1,129.2)
	\put(134.1,0){$x_{\max}^2$}
	\qbezier[41](20,129.2)(82.05,129.2)(144.1,129.2)
	\put(0,126.2){$y_{\max}^2$}
	\qbezier[41](20,66.8)(82.05,66.8)(144.1,66.8)
	\put(0,63.8){$y_{\min}^2$}
}{Diagrama representando un ejemplo del algoritmo iterativo aplicado al método
de fuerza bruta de Monte-Carlo con dos variables para $N_{simulaciones}= 25$,
$N_{best}=4$ y dos iteraciones}{FigIterative}

El algoritmo iterativo puede ser también fácilmente paralelizdo. No obstante,
este método es menos paralelizable con los de fuerza bruta puros puesto que la
paralelización debe ejecutarse en cada iteración (véase un diagrama de flujo en
la figura~\ref{FigIterativeParallelization}).

\psset{xunit=0.5mm,yunit=0.5mm}
\PSPICTURE{-105}{-130}{105}{-15}
{
	\tiny
	\rput(0,-15){1º iteración:}
	\rput(0,-20){Generación de $N_{simulaciones}$ conjuntos de parámetros
		empíricos}
	\psframe(-75,-25)(75,-10)
	\psline{->}(0,-25)(-60,-30)
	\psline{->}(0,-25)(0,-30)
	\psline{->}(0,-25)(60,-30)
	\rput(-60,-35){1ª tarea:}
	\rput(-60,-40){$N_{simulaciones}/N_{tareas}$ simulaciones}
	\psframe(-105,-30)(-15,-45)
	\rput(0,-37.5){$\cdots$}
	\rput(60,-35){$N_{tareas}$-ésima tarea:}
	\rput(60,-40){$N_{simulaciones}/N_{tareas}$ simulaciones}
	\psframe(15,-30)(105,-45)
	\psline{->}(-60,-45)(0,-50)
	\psline{->}(0,-45)(0,-50)
	\psline{->}(60,-45)(0,-50)
	\rput(0,-55){Obtención de $N_{best}$ conjuntos de parámetros empíricos}
	\psframe(-65,-50)(65,-60)
	\psline{->}(0,-60)(0,-65)
	\rput(0,-70){$\cdots$}
	\psline{->}(0,-75)(0,-80)
	\rput(0,-85){$N_{iteraciones}$-ésima iteración:}
	\rput(0,-90){Generación de $N_{simulaciones}$ conjuntos de parámetros
		empíricos}
	\psframe(-75,-95)(75,-80)
	\psline{->}(0,-95)(-60,-100)
	\psline{->}(0,-95)(0,-100)
	\psline{->}(0,-95)(60,-100)
	\rput(-60,-105){1ª tarea:}
	\rput(-60,-110){$N_{simulaciones}/N_{tareas}$ simulaciones}
	\psframe(-105,-100)(-15,-115)
	\rput(0,-107.5){$\cdots$}
	\rput(60,-105){$N_{tareas}$-ésima tarea:}
	\rput(60,-110){$N_{simulaciones}/N_{tareas}$ simulaciones}
	\psframe(15,-100)(105,-115)
	\psline{->}(-60,-115)(0,-120)
	\psline{->}(0,-115)(0,-120)
	\psline{->}(60,-115)(0,-120)
	\rput(0,-125){Obtención del conjunto óptimo de parámetros empíricos}
	\psframe(-65,-120)(65,-130)
}{Diagrama de flujo del esquema de paralelización seguido en MPCOTool para el
método iterativo}{FigIterativeParallelization}

\section{Método de ascenso de colinas}

Los métodos de fuerza bruta, barrido y Monte-Carlo, pueden combinarse también
con un algoritmo de ascenso de colinas. Definiendo el vector $\vec{r}_i$ como
la combinación óptima de variables obtenida en el paso $i$-ésimo, $\vec{r}_1$
como la combinación óptima de variables obtenida por el método de fuerza bruta y
definiendo el vector $\vec{s}_i$ como:
\EQ
{
	\vec{s}_1=\vec{0},\qquad
	\vec{s}_i=(1-relaxation)\,\vec{s}_{i-1}+relaxation\,\Delta\vec{r}_{i-1},
}{Eqs}
con $\Delta\vec{r}_{i-1}=\vec{r}_i+\vec{r}_{i-1}$ y $relaxtion$ el parámetro de
relajación, el método de ascenso prueba $N_{estimaciones}$ combinaciones de 
variables y elige el óptimo como:
\EQ
{
	\vec{r}_{i+1}=\mathrm{optimo}\PA{\vec{r}_i,\;\vec{r}_i+\vec{s}_i+\vec{t}_j},
	\;j=1,\cdots,N_{estimaciones}.
}{EqClimbing}
Si en un paso no se mejora el óptimo ($\vec{r}_i=\vec{r}_{i+1}$) entonces las
componentes del vector de ascenso $\vec{t}_j$ se dividen por dos y las 
$\vec{s}_{i+1}$ se anulan. El método se itera $N_{pasos}$ veces.

Aunque teóricamente el método de ascenso de colinas es el de convergencia más
rápida, también es el método de los implementados en MPCOTool que menores
ventajas obtiene de la paralelización. El método es casi secuencial y la
paralelización sólo puede hacerse en cada paso en las $N_{estimaciones}$
simulaciones necesarias para estimar el ascenso óptimo. En la
figura~\ref{FigClimbingParallelization} se muestra un diagrama de flujo del
esquma de paralelización seguido para este método.

\psset{xunit=0.5mm,yunit=0.5mm}
\PSPICTURE{-105}{-130}{105}{-15}
{
	\tiny
	\rput(0,-15){Paso 1º}
	\rput(0,-20){Generación de $N_{estimaciones}$ conjuntos de parámetros
		empíricos}
	\psframe(-75,-25)(75,-10)
	\psline{->}(0,-25)(-60,-30)
	\psline{->}(0,-25)(0,-30)
	\psline{->}(0,-25)(60,-30)
	\rput(-60,-35){Tarea 1ª:}
	\rput(-60,-40){$N_{estimaciones}/N_{tareas}$ simulaciones}
	\psframe(-105,-30)(-15,-45)
	\rput(0,-37.5){$\cdots$}
	\rput(60,-35){Tarea $N_{tareas}$-ésima:}
	\rput(60,-40){$N_{estimaciones}/N_{tareas}$ simulaciones}
	\psframe(15,-30)(105,-45)
	\psline{->}(-60,-45)(0,-50)
	\psline{->}(0,-45)(0,-50)
	\psline{->}(60,-45)(0,-50)
	\rput(0,-55){Obtención del conjunto óptimo de parámetros empíricos}
	\psframe(-65,-50)(65,-60)
	\psline{->}(0,-60)(0,-65)
	\rput(0,-70){$\cdots$}
	\psline{->}(0,-75)(0,-80)
	\rput(0,-85){Paso $N_{pasos}$-ésimo:}
	\rput(0,-90){Generación de $N_{estimaciones}$ conjuntos de parámetros
		empíricos}
	\psframe(-75,-95)(75,-80)
	\psline{->}(0,-95)(-60,-100)
	\psline{->}(0,-95)(0,-100)
	\psline{->}(0,-95)(60,-100)
	\rput(-60,-105){Tarea 1ª:}
	\rput(-60,-110){$N_{estimaciones}/N_{tareas}$ simulaciones}
	\psframe(-105,-100)(-15,-115)
	\rput(0,-107.5){$\cdots$}
	\rput(60,-105){Tarea $N_{tareas}$-ésima:}
	\rput(60,-110){$N_{estimaciones}/N_{tareas}$ simulaciones}
	\psframe(15,-100)(105,-115)
	\psline{->}(-60,-115)(0,-120)
	\psline{->}(0,-115)(0,-120)
	\psline{->}(60,-115)(0,-120)
	\rput(0,-125){Obtención del conjunto óptimo de parámetros empíricos}
	\psframe(-65,-120)(65,-130)
}{Diagrama de flujo del esquema de paralelización seguido en MPCOTool para el
método de ascenso de colinas}{FigClimbingParallelization}

MPCOTool usa dos métodos para construir los vectores $\vec{t}_j$:

\subsection{Ascenso por coordenadas}

El método genera los vectores $\vec{t}_j$ incrementando o decreciendo una sóla
variable:
\[
	\vec{t}_1=\MATRIX{c}{paso_1\\0\\0\\\vdots\\0},\quad
	\vec{t}_2=\MATRIX{c}{-paso_1\\0\\0\\\vdots\\0},\quad
	\vec{t}_3=\MATRIX{c}{0\\paso_2\\0\\\vdots\\0},
\]
\EQ
{
	\vec{t}_4=\MATRIX{c}{0\\-paso_2\\0\\\vdots\\0},\quad\cdots,\quad
	\vec{t}_{N_{estimaciones}}=\MATRIX{c}{0\\0\\0\\\vdots\\
	-paso_{N_{variables}}},
}{EqtDescent}
siendo $paso_j$ el tamaño de paso inicial para la variable $j$-ésima definido
por el usuario en el fichero principal de entrada. El número total de
estimaciones depende del número de variables:
\EQ{N_{estimaciones}=2\,N_{variables}}{EqNestimatesDescent}

\subsection{Ascenso aleatorio}

Los vectores $\vec{t}_j$ se construyen aleatoriamente:
\EQ
{
	\vec{t}_j=\MATRIX{c}{\PA{1-2\,r_{j,1}}\,paso_1\\\vdots\\
	\PA{1-2\,r_{j,k}}\,paso_k\\\vdots\\
	\PA{1-2\,r_{j,N_{variables}}}\,paso_{N_{variables}}},
}{EqtRandom}
con $r_{j,k}\in[0,1)$ números aleatorios.

En la figura~\ref{FigClimbing} se presenta un esquema para un sistema con dos
variables para ilustrar el modo de funcionamiento de los algoritmos de ascenso
por coordenadas y aleatorio.
\psset{xunit=0.45mm,yunit=0.45mm,runit=0.5mm}
\PSPICTURE{0}{0}{260}{100}
{
	\psline{->}(10,10)(10,90)
	\rput(15,95){$variable_2$}
	\psline{->}(10,10)(120,10)
	\rput(110,5){$variable_1$}
	\rput(20,15){$\vec{r}_{i-1}$}
	\pscircle*(20,20){1}
	\rput(55,34){$\vec{r}_i$}
	\pscircle*(55,40){1}
	\psline{->}(20,20)(55,40)
	\rput(30,36){$\Delta\vec{r}_{i-1}$}
	\psline{->}(55,40)(90,65)
	\rput(65,54){$\vec{s}_i$}
	\psline{->}(90,65)(90,85)
	\pscircle*(90,85){1}
	\rput(95,81){$\vec{t}_3$}
	\psline{->}(90,65)(110,65)
	\pscircle*(110,65){1}
	\rput(105,71){$\vec{t}_1$}
	\psline{->}(90,65)(70,65)
	\pscircle*(70,65){1}
	\rput(75,70){$\vec{t}_2$}
	\psline{->}(90,65)(90,45)
	\pscircle*(90,45){1}
	\rput(95,50){$\vec{t}_4$}
	\psline{->}(140,10)(140,90)
	\rput(145,95){$variable_2$}
	\psline{->}(140,10)(250,10)
	\rput(240,5){$variable_1$}
	\rput(150,15){$\vec{r}_{i-1}$}
	\pscircle*(150,20){1}
	\rput(185,34){$\vec{r}_i$}
	\pscircle*(185,40){1}
	\psline{->}(150,20)(185,40)
	\rput(160,36){$\Delta\vec{r}_{i-1}$}
	\psline{->}(185,40)(220,65)
	\rput(195,54){$\vec{s}_i$}
	\psline{->}(220,65)(207,75)
	\pscircle*(207,75){1}
	\rput(207,81){$\vec{t}_3$}
	\psline{->}(220,65)(228,68)
	\pscircle*(228,68){1}
	\rput(228,74){$\vec{t}_1$}
	\psline{->}(220,65)(212,49)
	\pscircle*(212,49){1}
	\rput(212,43){$\vec{t}_2$}
}{Pruebas de combinaciones de variables con los algoritmos de (izquierda)
ascenso por coordenadas y (derecha) aleatorio con $N_{estimaciones}=3$ en un
sistema de dos variables}{FigClimbing}

\section{Método genético}

MPCOTool también permite el uso de un método genético \cite{genetic} con sus
algoritmos por defecto. Está inspirado en las ideas de \citet{gaul}, pero ha
sido completamente reprogramado de cero usando librerías externas modernas. El
código en Genetic es también libre bajo una licencia de tipo BSD. La
figura~\ref{FigGeneticFlow} muestra el diagrama de flujo del método genético
por defecto implementado en Genetic.

\psset{xunit=0.5mm,yunit=0.5mm}
\PSPICTURE{-120}{-185}{120}{20}
{
	\tiny
	\rput(0,15){Generación de $N_{poblacion}$}
	\rput(0,10){genomas aleatorios}
	\psframe(-35,5)(35,20)
	\psline{->}(0,5)(0,0)
	\rput(0,-5){$generacion=1$}
	\psframe(-25,-10)(25,0)
	\psline{->}(0,-10)(0,-15)
	\rput(0,-20){Simulación de $N_{poblacion}$}
	\rput(0,-25){seres}
	\psframe(-40,-30)(40,-15)
	\psline{->}(0,-30)(0,-35)
	\rput(0,-40){Ordenación de $N_{poblacion}$ seres}
	\rput(0,-45){según el valor de la función objetivo}
	\psframe(-45,-50)(45,-35)
	\psline{->}(0,-50)(0,-55)
	\rput(0,-60){Eliminación de los peores}
	\rput(0,-65){$N_{mutacion}+N_{reproduccion}+N_{adaptacion}$ seres}
	\psframe(-65,-70)(65,-55)
	\psline{->}(0,-70)(-80,-75)
	\rput(-80,-80){Generación de $N_{mutacion}$}
	\rput(-80,-85){nuevos seres por mutación}
	\psframe(-115,-90)(-45,-75)
	\psline{->}(-80,-90)(-80,-95)
	\rput(-80,-100){Simulación de $N_{mutacion}$}
	\rput(-80,-105){nuevos seres mutados}
	\psframe(-115,-110)(-45,-95)
	\psline{->}(0,-70)(0,-75)
	\rput(0,-80){Generación de $N_{reproduccion}$}
	\rput(0,-85){nuevos seres por reproducción}
	\psframe(-40,-90)(40,-75)
	\psline{->}(0,-90)(0,-95)
	\rput(0,-100){Simulación de $N_{reproduccion}$}
	\rput(0,-105){nuevos seres reproducidos}
	\psframe(-40,-110)(40,-95)
	\psline{->}(0,-70)(82.5,-75)
	\rput(82.5,-80){Generación de $N_{adaptacion}$}
	\rput(82.5,-85){nuevos seres por adaptación}
	\psframe(120,-90)(45,-75)
	\psline{->}(82.5,-90)(82.5,-95)
	\rput(82.5,-100){Simulación de $N_{adaptacion}$}
	\rput(82.5,-105){nuevos seres adaptados}
	\psframe(120,-110)(45,-95)
	\psline{->}(-80,-110)(0,-115)
	\psline{->}(0,-110)(0,-115)
	\psline{->}(82.5,-110)(0,-115)
	\rput(0,-120){Ordenación de los viejos $N_{supervivientes}$ seres y de los}
	\rput(0,-125){nuevos $N_{mutacion}+N_{reproduccion}+N_{adaptacion}$}
	\rput(0,-130){seres según los valores de la función objetivo}
	\psframe(-65,-115)(65,-135)
	\psline{->}(0,-135)(0,-140)
	\rput(0,-145){Incrementar $+1$ $generation$}
	\psframe(-35,-140)(35,-150)
	\psline{->}(0,-150)(0,-155)
	\rput(0,-162.5){¿$generation<N_{generaciones}$?}
	\pspolygon(-55,-162.5)(0,-170)(55,-162.5)(0,-155)
	\psline{->}(-55,-162.5)(-120,-162.5)(-120,-62.5)(-65,-62.5)
	\rput(-55,-160){Sí}
	\rput(-5,-172.5){No}
	\psline{->}(0,-170)(0,-175)
	\rput(0,-180){Selección del mejor ser}
	\psframe(-30,-185)(30,-175)
}{Diagrama de flujo del método genético por defecto implementado en Genetic}
{FigGeneticFlow}

\subsection{El genoma}

Las varaibles a calibrar/optimizar son codificadas en Genetic usando una cadena
de bits: el genoma. Cuanto mayor es el número de bits asignado a una variable
mayor es su resolución. El número de bits asignado a cada variable, y de ahí el
tamaño del genoma, son fijos e iguales para todas las simulaciones. En la
figura~\ref{FigGenome} se muestra un ejemplo codificando tres variables. El
valor asignado a cada variable $x$ está determinado por los valores extremos
permitidos $x_{\min}$ and $x_{\max}$, el número binario asignado a la variable
en la región correspondiente del genoma $I_x$ y por el número de bits asignado a
la variable $N_x$ según la siguiente fórmula:
\EQ{x=x_{\min}+\frac{I_x}{2^{N_x}-1}\,\left(x_{\max}-x_{\min}\right).}{EqGenome}

\psset{unit=1mm}
\PSPICTURE{0}{3}{80}{30}
{
	\scriptsize
	\rput(40,27){Genoma}
	\rput(15,23){Variable 1}
	\pspolygon(0,15)(30,15)(30,20)(0,20)
	\rput(40,23){Variable 2}
	\pspolygon(30,15)(50,15)(50,20)(30,20)
	\rput(65,23){Variable 3}
	\pspolygon(50,15)(80,15)(80,20)(50,20)
	\psline{->}(10,12)(0,12)
	\rput(5,9){Bit menos}
	\rput(5,6){significativo}
	\psline{->}(20,12)(30,12)
	\rput(25,9){Bit más}
	\rput(25,6){significativo}
	\rput(2,17.5){1}
	\rput(4,17.5){0}
	\rput(6,17.5){0}
	\rput(8,17.5){1}
	\rput(10,17.5){0}
	\rput(12,17.5){0}
	\rput(14,17.5){1}
	\rput(16,17.5){1}
	\rput(18,17.5){1}
	\rput(20,17.5){1}
	\rput(22,17.5){1}
	\rput(24,17.5){1}
	\rput(26,17.5){0}
	\rput(28,17.5){1}
	\rput(32,17.5){1}
	\rput(34,17.5){0}
	\rput(36,17.5){0}
	\rput(38,17.5){0}
	\rput(40,17.5){0}
	\rput(42,17.5){0}
	\rput(44,17.5){0}
	\rput(46,17.5){0}
	\rput(48,17.5){0}
	\rput(52,17.5){1}
	\rput(54,17.5){1}
	\rput(56,17.5){1}
	\rput(58,17.5){1}
	\rput(60,17.5){0}
	\rput(62,17.5){1}
	\rput(64,17.5){0}
	\rput(66,17.5){0}
	\rput(68,17.5){0}
	\rput(70,17.5){0}
	\rput(72,17.5){1}
	\rput(74,17.5){1}
	\rput(76,17.5){1}
	\rput(78,17.5){1}
}{Ejemplo codificando tres variables a optimizar en un genoma. Primera y tercera
variables han sido codificadas con 14 bits y la segunda con 9 bits en este
ejemplo}{FigGenome}

\subsection{Supervivencia de los mejores individuos}

En una población con $N_{poblacion}$ individuos, en la primera generación se
simulan todos los casos. Las variables de entrada se obtienen del genoma de cada
individuo. Despueés, en cada generación, $N_{poblacion}\times R_{mutacion}$
individuos se generan por mutation, $N_{poblacion}\times R_{reproduccion}$ por
reproducción y $N_{poblacion}\times R_{adaptacion}$ por adaptación, obviamente
teniendo en cuenta redondeos. A partir de la segunda generación sólo se
se simulan los casos asociados a estos nuevos individuos ($N_{nuevos}$):
\EQ
{
	N_{nuevos}=N_{poblacion}
	\times\left(R_{mutacion}+R_{reproduccion}+R_{adaptacion}\right).
}{EqNew}
Por lo tanto, el número total de simulaciones ejecutadas por el algoritmo
genético es:
\EQ
{
	N_{total}=N_{poblacion}+\left(N_{generaciones}-1\right)\times N_{nuevos},
}{EqGeneticNumber}
con $N_{generaciones}$ el número de generaciones de nuevos individuos.
Los individuos de la anterior población que han obtenido peores valores en la
función objetivo son son reemplazados así que sólo los mejores
$N_{supervivientes}$ individuos sobreviven:
\EQ
{
	N_{supervivientes}=N_{poblacion}-N_{nuevos}.
}{EqSurvival}
Además, los ancestros que generan los nuevos individuos son elegidos entre los
supervivientes. Obviamente, para tener población superviviente con la que
generar nuevos individuos se debe cumplir:
\EQ{R_{mutacion}+R_{reproduccion}+R_{adaptacion}<1}{EqSurvivalCondition}
MPCOTool usa el criterio por defecto en Genetic, con una probabilidad
linealmente decreciente con el ordinal del conjunto ordenado de individuos
supervivientes (véase la figura~\ref{FigSelection}).

\PICTURE{250}{110}
{
	\scriptsize
	\put(10,20){\vector(0,1){80}}
	\put(10,20){\vector(1,0){235}}
	\put(0,102){Probabilidad de ser seleccionado como ancestro}
	\put(30,0){Población superviviente ordenada según los valores de la función
		objetivo}
	\multiput(20,20)(10,0){2}{\line(0,1){66}}
	\put(20,86){\line(1,0){10}}
	\put(22,10){1º}
	\multiput(40,20)(10,0){2}{\line(0,1){60}}
	\put(40,80){\line(1,0){10}}
	\put(42,10){2º}
	\multiput(60,20)(10,0){2}{\line(0,1){54}}
	\put(60,74){\line(1,0){10}}
	\put(62,10){3º}
	\multiput(80,20)(10,0){2}{\line(0,1){48}}
	\put(80,68){\line(1,0){10}}
	\put(82,10){4º}
	\multiput(100,20)(10,0){2}{\line(0,1){42}}
	\put(100,62){\line(1,0){10}}
	\put(140,10){...}
	\multiput(120,20)(10,0){2}{\line(0,1){36}}
	\put(120,56){\line(1,0){10}}
	\multiput(140,20)(10,0){2}{\line(0,1){30}}
	\put(140,50){\line(1,0){10}}
	\multiput(160,20)(10,0){2}{\line(0,1){24}}
	\put(160,44){\line(1,0){10}}
	\multiput(180,20)(10,0){2}{\line(0,1){18}}
	\put(180,38){\line(1,0){10}}
	\multiput(200,20)(10,0){2}{\line(0,1){12}}
	\put(200,32){\line(1,0){10}}
	\multiput(220,20)(10,0){2}{\line(0,1){6}}
	\put(220,26){\line(1,0){10}}
	\put(205,10){$N_{supervivientes}$-ésimo}
	\qbezier[54](10,90.5)(127.5,50.25)(245,20)
}{Probabilidad de un superviviente de ser seleccionado como ancestro de nuevos
individuos generados por los algoritmos de mutación, reproducción o adaptación}
{FigSelection}

\subsection{Algortimo de mutación}

En este algoritmo se hace una copia idéntica del genoma del ancestro excepto en
que se invierte un bit, elegido aleatoriamente con probabilidad uniforme. La
figura~\ref{FigMutation} muestra un ejemplo.
\psset{unit=1mm}
\PSPICTURE{0}{0}{80}{20}
{
	\scriptsize
	\rput(10,17.5){Ancestro}
	\pspolygon(20,15)(80,15)(80,20)(20,20)
	\rput(22,17.5){1}
	\rput(24,17.5){1}
	\rput(26,17.5){0}
	\rput(28,17.5){1}
	\rput(30,17.5){1}
	\rput(32,17.5){1}
	\rput(34,17.5){0}
	\rput(36,17.5){0}
	\rput(38,17.5){0}
	\rput(40,17.5){0}
	\rput(42,17.5){0}
	\rput(44,17.5){0}
	\rput(46,17.5){0}
	\rput(48,17.5){0}
	\rput(50,17.5){1}
	\rput(52,17.5){1}
	\rput(54,17.5){1}
	\rput(56,17.5){1}
	\rput(58,17.5){1}
	\rput(60,17.5){0}
	\rput(62,17.5){1}
	\rput(64,17.5){0}
	\rput(66,17.5){0}
	\rput(68,17.5){0}
	\rput(70,17.5){0}
	\rput(72,17.5){1}
	\rput(74,17.5){1}
	\rput(76,17.5){1}
	\rput(78,17.5){1}
	\rput(10,2.5){Hijo}
	\pspolygon(20,0)(80,0)(80,5)(20,5)
	\rput(22,2.5){1}
	\rput(24,2.5){1}
	\rput(26,2.5){0}
	\rput(28,2.5){1}
	\rput(30,2.5){1}
	\rput(32,2.5){1}
	\rput(34,2.5){0}
	\rput(36,2.5){1}
	\rput(38,2.5){0}
	\rput(40,2.5){0}
	\rput(42,2.5){0}
	\rput(44,2.5){0}
	\rput(46,2.5){0}
	\rput(48,2.5){0}
	\rput(50,2.5){1}
	\rput(52,2.5){1}
	\rput(54,2.5){1}
	\rput(56,2.5){1}
	\rput(58,2.5){1}
	\rput(60,2.5){0}
	\rput(62,2.5){1}
	\rput(64,2.5){0}
	\rput(66,2.5){0}
	\rput(68,2.5){0}
	\rput(70,2.5){0}
	\rput(72,2.5){1}
	\rput(74,2.5){1}
	\rput(76,2.5){1}
	\rput(78,2.5){1}
	\psline{->}(50,15)(50,5)
	\rput(60,10){Mutación}
	\pspolygon(35,15)(37,15)(37,20)(35,20)
	\pspolygon(35,5)(37,5)(37,0)(35,0)
	\psline{->}(32,10)(36,10)(36,15)
	\psline{->}(32,10)(36,10)(36,5)
	\rput(16,10){Inversión de un bit aleatorio}
}{Diagrama ilustrando un ejemplo de la generación de un nuevo individuo por
mutación}{FigMutation}

\subsection{Algoritmo de reproducción}

El algoritmo de reproducción por defecto en Genetic selecciona dos ancestros
diferentes entre la población superviviente y genera un nuevo individuo con los
mismos bits que los que resultan iguales en los genomas de ambos ancestros y con
bits aleatorios en los demás. El nuevo hijo tiene el mismo número de bits que
los antecesores pero distinto genoma. En la figura~\ref{FigReproduction} se
ilustra un diagrama del algoritmo.

\psset{unit=1mm}
\PSPICTURE{0}{0}{80}{20}
{
	\scriptsize
	\multido{\rb=0+7.5,\rt=5+7.5}{3}
	{
		\psframe[linecolor=gray,fillcolor=gray,fillstyle=solid](20,\rb)(23,\rt)
		\psframe[linecolor=gray,fillcolor=gray,fillstyle=solid](25,\rb)(29,\rt)
		\psframe[linecolor=gray,fillcolor=gray,fillstyle=solid](45,\rb)(47,\rt)
		\psframe[linecolor=gray,fillcolor=gray,fillstyle=solid](49,\rb)(51,\rt)
		\psframe[linecolor=gray,fillcolor=gray,fillstyle=solid](59,\rb)(61,\rt)
		\psframe[linecolor=gray,fillcolor=gray,fillstyle=solid](63,\rb)(67,\rt)
		\psframe[linecolor=gray,fillcolor=gray,fillstyle=solid](71,\rb)(75,\rt)
	}
	\rput(10,17.5){Ancestro 1º}
	\psframe(20,15)(80,20)
	\rput(22,17.5){1}
	\rput(24,17.5){1}
	\rput(26,17.5){0}
	\rput(28,17.5){1}
	\rput(30,17.5){1}
	\rput(32,17.5){1}
	\rput(34,17.5){0}
	\rput(36,17.5){0}
	\rput(38,17.5){0}
	\rput(40,17.5){0}
	\rput(42,17.5){0}
	\rput(44,17.5){0}
	\rput(46,17.5){0}
	\rput(48,17.5){0}
	\rput(50,17.5){1}
	\rput(52,17.5){1}
	\rput(54,17.5){1}
	\rput(56,17.5){1}
	\rput(58,17.5){1}
	\rput(60,17.5){0}
	\rput(62,17.5){1}
	\rput(64,17.5){0}
	\rput(66,17.5){0}
	\rput(68,17.5){0}
	\rput(70,17.5){0}
	\rput(72,17.5){1}
	\rput(74,17.5){1}
	\rput(76,17.5){1}
	\rput(78,17.5){1}
	\rput(10,2.5){Ancestro 2º}
	\psframe(20,0)(80,5)
	\rput(22,2.5){1}
	\rput(24,2.5){0}
	\rput(26,2.5){0}
	\rput(28,2.5){1}
	\rput(30,2.5){0}
	\rput(32,2.5){0}
	\rput(34,2.5){1}
	\rput(36,2.5){1}
	\rput(38,2.5){1}
	\rput(40,2.5){1}
	\rput(42,2.5){1}
	\rput(44,2.5){1}
	\rput(46,2.5){0}
	\rput(48,2.5){1}
	\rput(50,2.5){1}
	\rput(52,2.5){0}
	\rput(54,2.5){0}
	\rput(56,2.5){0}
	\rput(58,2.5){0}
	\rput(60,2.5){0}
	\rput(62,2.5){0}
	\rput(64,2.5){0}
	\rput(66,2.5){0}
	\rput(68,2.5){1}
	\rput(70,2.5){1}
	\rput(72,2.5){1}
	\rput(74,2.5){1}
	\rput(76,2.5){0}
	\rput(78,2.5){0}
	\rput(10,10){Descendiente}
	\psframe(20,7.5)(80,12.5)
	\rput(22,10){1}
	\rput(24,10){0}
	\rput(26,10){0}
	\rput(28,10){1}
	\rput(30,10){0}
	\rput(32,10){0}
	\rput(34,10){0}
	\rput(36,10){1}
	\rput(38,10){1}
	\rput(40,10){0}
	\rput(42,10){1}
	\rput(44,10){1}
	\rput(46,10){0}
	\rput(48,10){1}
	\rput(50,10){1}
	\rput(52,10){1}
	\rput(54,10){1}
	\rput(56,10){1}
	\rput(58,10){0}
	\rput(60,10){0}
	\rput(62,10){0}
	\rput(64,10){0}
	\rput(66,10){0}
	\rput(68,10){1}
	\rput(70,10){0}
	\rput(72,10){1}
	\rput(74,10){1}
	\rput(76,10){0}
	\rput(78,10){1}
	\psline{->}(50,5)(50,7.5)
	\psline{->}(50,15)(50,12.5)
	\psline{->}(10,5)(10,7.5)
	\psline{->}(10,15)(10,12.5)
}{Ejemplo da la generación de un nuevo individuo con el algoritmo por defecto de
Genetic. Nótese como los bits idénticos entre ambos antecesores (en gris) están
también presentes en el descendiente. El resto de los bits es aleatorio}
{FigReproduction}

\subsection{Algoritmo de adaptación}

Otro algoritmo se incluye en Genetic denominado ``adaptation'' aunque, en
sentido biológico, es más bien una mutación suave. Primero, se selecciona
aleatoriamente una variable codificada en el genoma con probabilidad uniforme.
Luego se invierte un bit elegido aleatoriamente pero con una probabilidad
decreciente según sea el bit más significativo. En la figura~\ref{FigAdaptation}
puede verse un ejemplo.

\psset{unit=1mm}
\PSPICTURE{-30}{-7.5}{80}{30}
{
	\scriptsize
	\rput(-10,17.5){Ancestro}
	\rput(15,23){Variable 1}
	\psframe(0,15)(30,20)
	\rput(40,23){Variable 2}
	\psframe(30,15)(50,20)
	\rput(65,23){Variable 3}
	\psline{->}(55,28)(65,28)(65,26)
	\rput(35,28){Selección aleatoria de una variable}
	\psframe(55,21)(75,26)
	\psframe(50,15)(80,20)
	\psline{->}(10,12)(0,12)
	\rput(5,9){Bit menos}
	\rput(5,6){significativo}
	\psline{->}(20,12)(30,12)
	\rput(25,9){Bit más}
	\rput(25,6){significativo}
	\rput(2,17.5){1}
	\rput(4,17.5){0}
	\rput(6,17.5){0}
	\rput(8,17.5){1}
	\rput(10,17.5){0}
	\rput(12,17.5){0}
	\rput(14,17.5){1}
	\rput(16,17.5){1}
	\rput(18,17.5){1}
	\rput(20,17.5){1}
	\rput(22,17.5){1}
	\rput(24,17.5){1}
	\rput(26,17.5){0}
	\rput(28,17.5){1}
	\rput(32,17.5){1}
	\rput(34,17.5){0}
	\rput(36,17.5){0}
	\rput(38,17.5){0}
	\rput(40,17.5){0}
	\rput(42,17.5){0}
	\rput(44,17.5){0}
	\rput(46,17.5){0}
	\rput(48,17.5){0}
	\rput(52,17.5){1}
	\rput(54,17.5){1}
	\rput(56,17.5){1}
	\rput(58,17.5){1}
	\rput(60,17.5){0}
	\rput(62,17.5){1}
	\rput(64,17.5){0}
	\rput(66,17.5){0}
	\rput(68,17.5){0}
	\rput(70,17.5){0}
	\rput(72,17.5){1}
	\rput(74,17.5){1}
	\rput(76,17.5){1}
	\rput(78,17.5){1}
	\rput(65,10){Probabilidad de selección}
	\rput(65,7){de un bit}
	\psframe[fillcolor=gray,fillstyle=solid](77,0)(79,0.5)
	\psframe[fillcolor=gray,fillstyle=solid](75,0)(77,1.0)
	\psframe[fillcolor=gray,fillstyle=solid](73,0)(75,1.5)
	\psframe[fillcolor=gray,fillstyle=solid](71,0)(73,2.0)
	\psframe[fillcolor=gray,fillstyle=solid](69,0)(71,2.5)
	\psframe[fillcolor=gray,fillstyle=solid](67,0)(69,3.0)
	\psframe[fillcolor=gray,fillstyle=solid](65,0)(67,3.5)
	\psframe[fillcolor=gray,fillstyle=solid](63,0)(65,4.0)
	\psframe[fillcolor=gray,fillstyle=solid](61,0)(63,4.5)
	\psframe[fillcolor=gray,fillstyle=solid](59,0)(61,5.0)
	\psframe[fillcolor=gray,fillstyle=solid](57,0)(59,5.5)
	\psframe[fillcolor=gray,fillstyle=solid](55,0)(57,6.0)
	\psframe[fillcolor=gray,fillstyle=solid](53,0)(55,6.5)
	\psframe[fillcolor=gray,fillstyle=solid](51,0)(53,7.0)
	\rput(-10,-5){Descendiente}
	\psframe(0,-2.5)(30,-7.5)
	\psframe(30,-2.5)(50,-7.5)
	\psframe(50,-2.5)(80,-7.5)
	\rput(2,-5){1}
	\rput(4,-5){0}
	\rput(6,-5){0}
	\rput(8,-5){1}
	\rput(10,-5){0}
	\rput(12,-5){0}
	\rput(14,-5){1}
	\rput(16,-5){1}
	\rput(18,-5){1}
	\rput(20,-5){1}
	\rput(22,-5){1}
	\rput(24,-5){1}
	\rput(26,-5){0}
	\rput(28,-5){1}
	\rput(32,-5){1}
	\rput(34,-5){0}
	\rput(36,-5){0}
	\rput(38,-5){0}
	\rput(40,-5){0}
	\rput(42,-5){0}
	\rput(44,-5){0}
	\rput(46,-5){0}
	\rput(48,-5){0}
	\rput(52,-5){1}
	\rput(54,-5){1}
	\rput(56,-5){0}
	\rput(58,-5){1}
	\rput(60,-5){0}
	\rput(62,-5){1}
	\rput(64,-5){0}
	\rput(66,-5){0}
	\rput(68,-5){0}
	\rput(70,-5){0}
	\rput(72,-5){1}
	\rput(74,-5){1}
	\rput(76,-5){1}
	\rput(78,-5){1}
	\psline{->}(-10,15)(-10,-2.5)
	\rput(-20,6.25){Adaptación}
	\psframe(55,-7.5)(57,-2.5)
	\psframe(55,15)(57,20)
}{Ejemplo de generación de un nuevo individuo a partir de un ancestro por el
algoritmo de adaptación}{FigAdaptation}

Este algoritmo es similar al de mutación descrito previamente pero, puesto que
la probabilidad de afectar bit menos significativos es mayor, también lo es la
probabilidad de producir cambios pequeños.

\subsection{Paralelización}

El método genético es también fácilmente paralelizable siguiendo un esquema
similar al del algoritmo iterativo, como puede verse en la
figura~\ref{FigGeneticParallelization}.

\psset{xunit=0.5mm,yunit=0.5mm}
\PSPICTURE{-100}{-185}{100}{-15}
{
	\tiny
	\rput(0,-15){Generación 1ª:}
	\rput(0,-20){Generación de $N_{poblacion}$ conjuntos de parámetros
		empíricos}
	\psframe(-70,-25)(70,-10)
	\psline{->}(0,-25)(-60,-30)
	\psline{->}(0,-25)(0,-30)
	\psline{->}(0,-25)(60,-30)
	\rput(-60,-35){Tarea 1ª:}
	\rput(-60,-40){$N_{poblacion}/N_{tareas}$ simulaciones}
	\psframe(-100,-30)(-20,-45)
	\rput(0,-37.5){$\cdots$}
	\rput(60,-35){Tarea $N_{tareas}$-ésima:}
	\rput(60,-40){$N_{poblacion}/N_{tareas}$ simulaciones}
	\psframe(20,-30)(100,-45)
	\psline{->}(-60,-45)(0,-50)
	\psline{->}(0,-45)(0,-50)
	\psline{->}(60,-45)(0,-50)
	\rput(0,-55){Obtención de $N_{supervivientes}$ conjuntos de parámetros
		empíricos}
	\psframe(-75,-50)(75,-60)
	\psline{->}(0,-60)(0,-65)
	\rput(0,-70){Generación 2ª:}
	\rput(0,-75){Generación de $N_{nuevos}$ conjuntos de parámetros empíricos}
	\psframe(-65,-80)(65,-65)
	\psline{->}(0,-80)(-60,-85)
	\psline{->}(0,-80)(0,-85)
	\psline{->}(0,-80)(60,-85)
	\rput(-60,-90){Tarea 1ª:}
	\rput(-60,-95){$N_{nuevos}/N_{tareas}$ simulaciones}
	\psframe(-100,-85)(-20,-100)
	\rput(0,-92.5){$\cdots$}
	\rput(60,-90){Tarea $N_{tareas}$-ésima:}
	\rput(60,-95){$N_{nuevos}/N_{tareas}$ simulaciones}
	\psframe(20,-85)(100,-100)
	\psline{->}(-55,-100)(0,-105)
	\psline{->}(0,-100)(0,-105)
	\psline{->}(55,-100)(0,-105)
	\rput(0,-110){Obtención de $N_{supervivientes}$ conjuntos de parámetros
		empíricos}
	\psframe(-75,-105)(75,-115)
	\psline{->}(0,-115)(0,-120)
	\rput(0,-125){$\cdots$}
	\psline{->}(0,-130)(0,-135)
	\rput(0,-140){Generación $N_{generaciones}$-ésima:}
	\rput(0,-145){Generación de $N_{nuevos}$ conjuntos de parámetros empíricos}
	\psframe(-65,-150)(65,-135)
	\psline{->}(0,-150)(-60,-155)
	\psline{->}(0,-150)(0,-155)
	\psline{->}(0,-150)(60,-155)
	\rput(-60,-160){Tarea 1ª:}
	\rput(-60,-165){$N_{nuevos}/N_{tareas}$ simulaciones}
	\psframe(-100,-155)(-20,-170)
	\rput(0,-162.5){$\cdots$}
	\rput(60,-160){Tarea $N_{tareas}$-ésima:}
	\rput(60,-165){$N_{nuevos}/N_{tareas}$ simulaciones}
	\psframe(20,-155)(100,-170)
	\psline{->}(-55,-170)(0,-175)
	\psline{->}(0,-170)(0,-175)
	\psline{->}(55,-170)(0,-175)
	\rput(0,-180){Obtención del conjunto óptimo de parámetros empíricos}
	\psframe(-65,-175)(65,-185)
}{Diagrama de flujo del esquema de paralelización seguido en Genetic para el
método genético}{FigGeneticParallelization}

\clearpage
\renewcommand{\bibname}{Referencias}
\addcontentsline{toc}{chapter}{\bibname}
\bibliography{bib}

\end{document}
